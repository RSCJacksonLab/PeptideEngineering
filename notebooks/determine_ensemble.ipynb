{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from scipy.stats.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine results into a single dataframe\n",
    "res = {\"embedding\": [], \"model\": [], \"k\": [], \"trn_mae\": [], \"trn_r2\": [], \"val_mae\": [], \"val_r2\": [], \"tst_mae\": [], \"tst_r2\": []}\n",
    "\n",
    "name = \"../results/ncv\"\n",
    "\n",
    "for emb in os.listdir(f\"../{name}/\"):\n",
    "    for model in os.listdir(f\"../{name}/{emb}\"):\n",
    "        df = pd.read_csv(f\"../{name}/{emb}/{model}/nCV_results.csv\")\n",
    "        res[\"embedding\"] += [emb] * len(df)\n",
    "        res[\"model\"] += [model] * len(df)\n",
    "        res[\"k\"] += df.k.tolist()\n",
    "        res[\"trn_mae\"] += df.trn_mae.tolist()\n",
    "        res[\"trn_r2\"] += df.trn_r2.tolist()\n",
    "        res[\"val_mae\"] += df.val_mae.tolist()\n",
    "        res[\"val_r2\"] += df.val_r2.tolist()\n",
    "        res[\"tst_mae\"] += df.tst_mae.tolist()\n",
    "        res[\"tst_r2\"] += df.tst_r2.tolist()\n",
    "\n",
    "res_df = pd.DataFrame(res)\n",
    "heatmap_res = res_df.groupby([\"model\", \"embedding\"]).mean()[[\"trn_r2\", \"val_r2\", \"tst_r2\"]]\n",
    "\n",
    "display(heatmap_res.sort_values(\"tst_r2\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler class to scale predictions\n",
    "class MinMaxScaler:\n",
    "\n",
    "    def __init__(self, y):\n",
    "        self.min_y = np.min(y)\n",
    "        self.max_y = np.max(y)\n",
    "    \n",
    "    def transform(self, y):\n",
    "        y_scaled = (y - self.min_y)/(self.max_y - self.min_y)\n",
    "        return y_scaled\n",
    "\n",
    "    def invert(self, y):\n",
    "        y_orig = y*(self.max_y - self.min_y) + self.min_y\n",
    "        return y_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary containing errors for each model with appropriate R2\n",
    "error_results = {\n",
    "    \"Model\": [],\n",
    "    \"Encoding\": [],\n",
    "    \"Predictions\": [],\n",
    "    \"Actual\": [],\n",
    "    \"Error\": [],\n",
    "    \"Mean-error\": []\n",
    "}\n",
    "\n",
    "for emb in os.listdir(f\"../{name}/\"):\n",
    "    for model in os.listdir(f\"../{name}/{emb}\"):\n",
    "        df = pd.read_csv(f\"../{name}/{emb}/{model}/nCV_results.csv\")\n",
    "        if np.mean(df[\"tst_r2\"].to_numpy()) > 0.17: \n",
    "            skl_model = pkl.load(open(f\"../{name}/{emb}/{model}/final_model.sav\", \"rb\"))\n",
    "\n",
    "            raw_ic50 = np.load(\"../data/data/joint_peptide_channel_encodings/IC50_raw.npy\")   \n",
    "            scaler = MinMaxScaler(raw_ic50)\n",
    "            y_scaled = scaler.transform(raw_ic50)\n",
    "\n",
    "            seqs = np.load(f\"../data/data/joint_peptide_channel_encodings/{emb}.npy\")\n",
    "\n",
    "            preds = skl_model.predict(seqs)\n",
    "\n",
    "            error_results[\"Model\"].append(model)\n",
    "            error_results[\"Encoding\"].append(emb)\n",
    "            error_results[\"Predictions\"].append(preds)\n",
    "            error_results[\"Actual\"].append(y_scaled)\n",
    "            error_results[\"Error\"].append(y_scaled - preds)\n",
    "            error_results[\"Mean-error\"].append(np.mean(np.abs(y_scaled - preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_ensemble(exclude_idx, actual_ls, pred_ls, error_ls):\n",
    "    best_corr_pair = (None, None)\n",
    "    best_corr = 1\n",
    "    for i in range(len(error_ls)):\n",
    "        for j in range(i):\n",
    "            if i in exclude_idx or j in exclude_idx:\n",
    "                continue\n",
    "            corr = pearsonr(error_ls[i], error_ls[j])\n",
    "            if corr < best_corr:\n",
    "                best_corr = corr\n",
    "                best_corr_pair = (i, j)\n",
    "    ens_pred = pred_ls[best_corr_pair[0]] + pred_ls[best_corr_pair[1]]/2\n",
    "    ens_error = actual_ls - ens_pred\n",
    "    mean_error = np.mean(np.abs(ens_error))\n",
    "    return best_corr_pair, best_corr, mean_error\n",
    "        \n",
    "def add_model(exclude_idx, actual_ls, pred_ls, ens_idx, error_ls):\n",
    "    best_corr_add = None\n",
    "    best_corr = 1\n",
    "    for i in range(len(error_ls)):\n",
    "        if i in exclude_idx:\n",
    "            continue\n",
    "        corr = pearsonr(error_ls[i], error_ls[j])\n",
    "        if corr < best_corr:\n",
    "            best_corr = corr\n",
    "            best_corr_add = i\n",
    "    ens_preds = pred_ls[best_corr_add]\n",
    "    ens_idx += [best_corr_add]\n",
    "    for idx in ens_idx:\n",
    "        ens_preds = ens_preds + pred_ls[idx]\n",
    "    ens_preds /= len(ens_preds) + 1\n",
    "    ens_error = actual_ls - ens_preds\n",
    "    mean_error = np.mean(np.abs(ens_error))\n",
    "    return ens_idx, best_corr, mean_error, best_corr_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {\n",
    "    \"ens_idx\": [],\n",
    "    \"ens_error\": [],\n",
    "    \"corr_of_added\": []\n",
    "}\n",
    "# excluding GBT with ST-score due to outlying train score\n",
    "excl_ls = [4]\n",
    "ens_idx, best_corr, ens_err = start_ensemble(\n",
    "    excl_ls, \n",
    "    error_results[\"Actual\"][0],\n",
    "    error_results[\"Predictions\"],\n",
    "    error_results[\"Error\"],\n",
    ")\n",
    "\n",
    "res[\"ens_error\"].append(ens_idx)\n",
    "res[\"ens_error\"].append(ens_err)\n",
    "res[\"corr_of_added\"].append(best_corr)\n",
    "\n",
    "# while there are models remaining\n",
    "while len(excl_ls) < len(error_results[\"Actual\"]):\n",
    "    ens_idx, best_corr, ens_err, added_idx = add_model(\n",
    "        excl_ls, \n",
    "        error_results[\"Actual\"][0], \n",
    "        error_results[\"Predictions\"], \n",
    "        ens_idx, \n",
    "        error_results[\"Error\"]\n",
    "    )\n",
    "    excl_ls += [added_idx]\n",
    "    \n",
    "    res[\"ens_error\"].append(ens_idx)\n",
    "    res[\"ens_error\"].append(ens_err)\n",
    "    res[\"corr_of_added\"].append(best_corr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
